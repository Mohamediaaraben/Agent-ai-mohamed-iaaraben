{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Collection Tasks with WebArchiverAgent\n",
    "\n",
    "### Why would we want this?\n",
    "As part of a larger pipeline, `WebArchiverAgent` accomplishes the task of automatic retrieval and storage of online content for numerous downstream tasks.  \n",
    "This task is facilitated by a headless Selenium webdriver. \n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install \"pyautogen[websurfer]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that we have the WebDrivers present for Selenium\n",
    "Following the instructions in [Selenium Documentation](https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location/#download-the-driver), \n",
    "we first download the web driver for our browser of choice, or all 3: [Edge](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/?form=MA13LH#downloads), [Firefox](https://github.com/mozilla/geckodriver/releases), [Chrome](https://chromedriver.chromium.org/downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither powershell nor pwsh is installed.\n"
     ]
    }
   ],
   "source": [
    "# %%capture --no-stderr\n",
    "import os\n",
    "import logging\n",
    "import autogen\n",
    "from PIL import Image\n",
    "from IPython.core.display_functions import display\n",
    "from autogen.agentchat.contrib.web_archiver_agent import WebArchiverAgent\n",
    "from autogen.agentchat.user_proxy_agent import UserProxyAgent\n",
    "from autogen.oai import config_list_from_json\n",
    "from autogen.browser_utils import display_binary_image\n",
    "from autogen.browser_utils import get_file_path_from_url\n",
    "\n",
    "# Get the logger instance for the current module (__name__).\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n",
    "\n",
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well).\n",
    "\n",
    "The WebSurferAgent uses a combination of models. GPT-4 and GPT-3.5-turbo-16 are recommended.\n",
    "\n",
    "Your json config should look something like the following:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your OpenAI API key here>\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"api_key\": \"<your OpenAI API key here>\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "        # filter_dict={\"model\": [\"Sakura-SOLAR-Instruct-f16\"]},\n",
    "        filter_dict={\n",
    "            \"model\": [\"gpt-3.5-turbo\"]\n",
    "        },  # , \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-4-1106-preview\"]},\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "summarizer_llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "        # filter_dict={\"model\": [\"Sakura-SOLAR-Instruct-f16\"]},\n",
    "        filter_dict={\"model\": [\"gpt-3.5-turbo\"]},\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Bing\n",
    "\n",
    "For WebSurferAgent to be reasonably useful, it needs to be able to search the web -- and that means it needs a Bing API key. \n",
    "You can read more about how to get an API on the [Bing Web Search API](https://www.microsoft.com/en-us/bing/apis/bing-web-search-api) page.\n",
    "\n",
    "Once you have your key, either set it as the `BING_API_KEY` system environment variable, or simply input your key below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_api_key = os.environ[\"BING_API_KEY\"] if \"BING_API_KEY\" in os.environ else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where our web content will be stored, we'll use this at the end of the notebook\n",
    "storage_path = \"./content\"\n",
    "\n",
    "web_archiver_agent = WebArchiverAgent(\n",
    "    name=\"ContentAgent\",  # Choose any name you prefer\n",
    "    system_message=\"You are data collection agent specializing in content on the web.\",\n",
    "    max_depth=0,\n",
    "    llm_config=llm_config,\n",
    "    max_consecutive_auto_reply=0,\n",
    "    silent=False,  # *NEW* In case we want to hear the inner-conversation,\n",
    "    storage_path=storage_path,  # *NEW* This is where our archived content is stored, defaulting to `./content`\n",
    "    browser_config={\n",
    "        \"bing_api_key\": bing_api_key,\n",
    "        \"type\": \"selenium\",  # *NEW* Here we specify that we intend to use our headless GUI browser. The default setting is \"text\".\n",
    "        \"browser\": \"edge\",  # *NEW* We'll use the edge browser for these tests.  Choices include 'edge', 'firefox', and 'chrome'\n",
    "        # \"resolution\": (1400,900), # *NEW* we specify the browser window size.  The default is (1920,5200)\n",
    "        \"render_text\": False,  # *NEW* We still have the option to convert the output to text and render it on the screen\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define the user agent\n",
    "user_proxy = autogen.agentchat.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    default_auto_reply=\"\",\n",
    "    is_termination_msg=lambda x: True,\n",
    "    max_consecutive_auto_reply=0,\n",
    ")\n",
    "\n",
    "# We register our collection function as the default response\n",
    "web_archiver_agent.register_reply(user_proxy, web_archiver_agent.collect_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take it for a spin!  \n",
    "The Autogen open-source framework has an academic paper on arxiv.org!  We'd certainly be interested to have that in our archives for later retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to ContentAgent):\n",
      "\n",
      "https://arxiv.org/abs/2308.08155\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to user_proxy):\n",
      "\n",
      "Success: archived the following links in your chosen location ./content/ <-- https://arxiv.org/abs/2308.08155\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': 'https://arxiv.org/abs/2308.08155', 'role': 'assistant'}, {'content': 'Success: archived the following links in your chosen location ./content/ <-- https://arxiv.org/abs/2308.08155', 'role': 'user'}], summary='Success: archived the following links in your chosen location ./content/ <-- https://arxiv.org/abs/2308.08155', cost=({'total_cost': 0}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"https://arxiv.org/abs/2308.08155\"\n",
    "\n",
    "user_proxy.initiate_chat(web_archiver_agent, message=link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll try another, this time the examples page from the Autogen official website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to ContentAgent):\n",
      "\n",
      "https://microsoft.github.io/autogen/docs/Examples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Examples`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Automated Multi Agent Chat​`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation. Please find documentation about this feature here.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation.\n",
      "Please find documentation about this feature <a href=\"/autogen/docs/Use-Cases/agent_chat\">here</a>.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Links to notebook examples:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Code Generation, Execution, and Debugging`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p><strong>Code Generation, Execution, and Debugging</strong></p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Multi-Agent Collaboration (>3 Agents)`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Sequential Multi-Agent Chats`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Applications`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Tool Use`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Human Involvement`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Agent Teaching and Learning`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Multi-Agent Chat with OpenAI Assistants in the loop`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Multimodal Agent`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Long Context Handling`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Evaluation and Assessment`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Automatic Agent Building`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Enhanced Inferences​`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Utilities​`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Inference Hyperparameters Tuning​`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```AutoGen offers a cost-effective hyperparameter optimization technique EcoOptiGen for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them. Please find documentation about this feature here.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>AutoGen offers a cost-effective hyperparameter optimization technique <a href=\"https://arxiv.org/abs/2303.04673\" rel=\"noopener noreferrer\" target=\"_blank\">EcoOptiGen</a> for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them.\n",
      "Please find documentation about this feature <a href=\"/autogen/docs/Use-Cases/enhanced_inference\">here</a>.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `Examples | AutoGen`, Data: ```Links to notebook examples:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'generator', 'content': 'Docusaurus v3.1.1'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'data-rh': 'true', 'name': 'twitter:card', 'content': 'summary_large_image'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'data-rh': 'true', 'property': 'og:locale', 'content': 'en'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'data-rh': 'true', 'name': 'docusaurus_locale', 'content': 'en'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'data-rh': 'true', 'name': 'docsearch:language', 'content': 'en'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'viewport', 'content': 'width=device-width, initial-scale=1.0', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'docusaurus_version', 'content': 'current', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'docusaurus_tag', 'content': 'docs-default-current', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'docsearch:version', 'content': 'current', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'docsearch:docusaurus_tag', 'content': 'docs-default-current', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:title', 'content': 'Examples | AutoGen', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'description', 'content': 'Automated Multi Agent Chat', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:description', 'content': 'Automated Multi Agent Chat', 'data-rh': 'true'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to user_proxy):\n",
      "\n",
      "Success: archived the following links in your chosen location ./content/ <-- https://microsoft.github.io/autogen/docs/Examples\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': 'https://microsoft.github.io/autogen/docs/Examples', 'role': 'assistant'}, {'content': 'Success: archived the following links in your chosen location ./content/ <-- https://microsoft.github.io/autogen/docs/Examples', 'role': 'user'}], summary='Success: archived the following links in your chosen location ./content/ <-- https://microsoft.github.io/autogen/docs/Examples', cost=({'total_cost': 0}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"https://microsoft.github.io/autogen/docs/Examples\"\n",
    "user_proxy.initiate_chat(web_archiver_agent, message=link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of communication taking place when listening to the inner-dialog.  The agent needs to confirm relevance of various pieces of content so its not storing advertisements or content not associated with the page topic.\n",
    "\n",
    "### We'll collect one more recent and very interesting publication by the good scientists at Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to ContentAgent):\n",
      "\n",
      "https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Global`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Microsoft Research Blog`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```GraphRAG: Unlocking LLM discovery on narrative private data`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Published February 13, 2024`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p class=\"single-post__header-date\">\n",
      "\t\t\t\tPublished\t\t\t\t<time datetime=\"2024-02-13T12:00:00-08:00\" itemprop=\"datePublished\">\n",
      "\t\t\t\t\tFebruary 13, 2024\t\t\t\t</time>\n",
      "</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```By Jonathan Larson , Senior Principal Data Architect Steven Truitt , Principal Program Manager`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Share this page`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Perhaps the greatest challenge – and opportunity – of LLMs is extending their powerful capabilities to solve problems beyond the data on which they have been trained, and to achieve comparable results with data the LLM has never seen.  This opens new possibilities in data investigation, such as identifying themes and semantic concepts with context and grounding on datasets.  In this post, we introduce GraphRAG, created by Microsoft Research, as a significant advance in enhancing the capability of LLMs.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Perhaps the greatest challenge – and opportunity – of LLMs is extending their powerful capabilities to solve problems beyond the data on which they have been trained, and to achieve comparable results with data the LLM has never seen.  This opens new possibilities in data investigation, such as identifying themes and semantic concepts with context and grounding on datasets.  In this post, we introduce GraphRAG, created by Microsoft Research, as a significant advance in enhancing the capability of LLMs.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Retrieval-Augmented Generation (RAG) is a technique to search for information based on a user query and provide the results as reference for an AI answer to be generated. This technique is an important part of most LLM-based tools and the majority of RAG approaches use vector similarity as the search technique. GraphRAG uses LLM-generated knowledge graphs to provide substantial improvements in question-and-answer performance when conducting document analysis of complex information.  This builds upon our recent research, which points to the power of prompt augmentation when performing discovery on private datasets. Here, we define private dataset as data that the LLM is not trained on and has never seen before, such as an enterprise’s proprietary research, business documents, or communications. Baseline RAG1 was created to help solve this problem, but we observe situations where baseline RAG performs very poorly. For example:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Retrieval-Augmented Generation (RAG) is a technique to search for information based on a user query and provide the results as reference for an AI answer to be generated. This technique is an important part of most LLM-based tools and the majority of RAG approaches use vector similarity as the search technique. GraphRAG uses LLM-generated knowledge graphs to provide substantial improvements in question-and-answer performance when conducting document analysis of complex information.  This builds upon our recent <a href=\"https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/\" rel=\"noreferrer noopener\" target=\"_blank\">research</a>, which points to the power of prompt augmentation when performing discovery on <em>private datasets</em>. Here, we define <em>private dataset </em>as data that the LLM is not trained on and has never seen before, such as an enterprise’s proprietary research, business documents, or communications. <em>Baseline RAG</em><sup><a href=\"#baseline-RAG\">1</a></sup> was created to help solve this problem, but we observe situations where baseline RAG performs very poorly.  For example:</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```To address this, the tech community is working to develop methods that extend and enhance RAG (e.g., LlamaIndex (opens in new tab)).  Microsoft Research’s new approach, GraphRAG, uses the LLM to create a knowledge graph based on the private dataset.  This graph is then used alongside graph machine learning to perform prompt augmentation at query time.  GraphRAG shows substantial improvement in answering the two classes of questions described above, demonstrating intelligence or mastery that outperforms other approaches previously applied to private datasets.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>To address this, the tech community is working to develop methods that extend and enhance RAG (e.g., <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://www.llamaindex.ai/\" rel=\"noreferrer noopener\" target=\"_blank\">LlamaIndex<span class=\"sr-only\"> (opens in new tab)</span></a>).  Microsoft Research’s new approach, GraphRAG, uses the LLM to create a knowledge graph based on the private dataset.  This graph is then used alongside graph machine learning to perform prompt augmentation at query time.  GraphRAG shows substantial improvement in answering the two classes of questions described above, demonstrating intelligence or mastery that outperforms other approaches previously applied to private datasets.   </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Applying RAG to private datasets`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```To demonstrate the effectiveness of GraphRAG, let’s start with an investigation using the Violent Incident Information from News Articles (VIINA) dataset (opens in new tab).  This dataset was chosen due to its complexity and the presence of differing opinions and partial information.  It is a messy real-world test case that was recent enough not to be included in the LLM base model’s training.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>To demonstrate the effectiveness of GraphRAG, let’s start with an investigation using the Violent Incident Information from News Articles (VIINA) <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/zhukovyuri/VIINA\" rel=\"noreferrer noopener\" target=\"_blank\">dataset<span class=\"sr-only\"> (opens in new tab)</span></a>.  This dataset was chosen due to its complexity and the presence of differing opinions and partial information.  It is a messy real-world test case that was recent enough not to be included in the LLM base model’s training.  </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```For this research, we use thousands of news articles from both Russian and Ukrainian news sources for the month of June 2023, translated into English, to create a private dataset on which we will perform our LLM-based retrieval.  The dataset is far too large to fit into an LLM context window, thus demanding a RAG approach.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>For this research, we use thousands of news articles from both Russian and Ukrainian news sources for the month of June 2023, translated into English, to create a private dataset on which we will perform our LLM-based retrieval.  The dataset is far too large to fit into an LLM context window, thus demanding a RAG approach.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```We start with an exploratory query, which we pose to both a baseline RAG system and to our new approach, GraphRAG:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>We start with an exploratory query, which we pose to both a baseline RAG system and to our new approach, GraphRAG:</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Query: “What is Novorossiya?”`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```In these results, we can see both systems perform well – highlighting a class of query on which baseline RAG performs well.  Let’s try a query that requires connecting the dots:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>In these results, we can see both systems perform well – highlighting a class of query on which baseline RAG performs well.  Let’s try a query that requires connecting the dots:</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Query: “What has Novorossiya done?”`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Baseline RAG fails to answer this question.  Looking at the source documents inserted into the context window (Figure 1), none of the text segments discuss Novorossiya, resulting in this failure.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Baseline RAG fails to answer this question.  Looking at the source documents inserted into the context window (Figure 1), none of the text segments discuss Novorossiya, resulting in this failure.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```In comparison, the GraphRAG approach discovered an entity in the query, Novorossiya.  This allows the LLM to ground itself in the graph and results in a superior answer that contains provenance through links to the original supporting text.  For example, Figure 2 below shows the exact content the LLM used for the LLM-generated statement, “Novorossiya has been implicated in plans to blow up ATMs.” We see the snippet from the raw source documents (after English translation) that the LLM used to support the assertion that a specific bank was a target for Novorossiya via the relationship that exists between the two entities in the graph.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>In comparison, the GraphRAG approach discovered an entity in the query, Novorossiya.  This allows the LLM to ground itself in the graph and results in a superior answer that contains provenance through links to the original supporting text.  For example, Figure 2 below shows the exact content the LLM used for the LLM-generated statement, “Novorossiya has been implicated in plans to blow up ATMs.” We see the snippet from the raw source documents (after English translation) that the LLM used to support the assertion that a specific bank was a target for Novorossiya via the relationship that exists between the two entities in the graph. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```By using the LLM-generated knowledge graph, GraphRAG vastly improves the “retrieval” portion of RAG, populating the context window with higher relevance content, resulting in better answers and capturing evidence provenance.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>By using the LLM-generated knowledge graph, GraphRAG vastly improves the “retrieval” portion of RAG, populating the context window with higher relevance content, resulting in better answers and capturing evidence provenance. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Being able to trust and verify LLM-generated results is always important.  We care that the results are factually correct, coherent, and accurately represent content found in the source material. GraphRAG provides the provenance, or source grounding information, as it generates each response.  It demonstrates that an answer is grounded in the dataset.  Having the cited source for each assertion readily available also enables a human user to quickly and accurately audit the LLM’s output directly against the original source material.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Being able to trust and verify LLM-generated results is always important.  We care that the results are factually correct, coherent, and accurately represent content found in the source material. GraphRAG provides the provenance, or source grounding information, as it generates each response.  It demonstrates that an answer is grounded in the dataset.  Having the cited source for each assertion readily available also enables a human user to quickly and accurately audit the LLM’s output directly against the original source material.   </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```However, this isn’t all that’s possible using GraphRAG.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>However, this isn’t all that’s possible using GraphRAG. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Whole dataset reasoning`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<h2 class=\"wp-block-heading\" id=\"whole-dataset-reasoning\">Whole dataset reasoning </h2>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Baseline RAG struggles with queries that require aggregation of information across the dataset to compose an answer. Queries such as “What are the top 5 themes in the data?” perform terribly because baseline RAG relies on a vector search of semantically similar text content within the dataset. There is nothing in the query to direct it to the correct information.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Baseline RAG struggles with queries that require aggregation of information across the dataset to compose an answer. Queries such as “What are the top 5 themes in the data?” perform terribly because baseline RAG relies on a vector search of semantically similar text content within the dataset. There is nothing in the query to direct it to the correct information. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```However, with GraphRAG we can answer such questions, because the structure of the LLM-generated knowledge graph tells us about the structure (and thus themes) of the dataset as a whole.  This allows the private dataset to be organized into meaningful semantic clusters that are pre-summarized.  The LLM uses these clusters to summarize these themes when responding to a user query.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>However, with GraphRAG we <em>can</em> answer such questions, because the structure of the LLM-generated knowledge graph tells us about the structure (and thus themes) of the dataset as a whole.  This allows the private dataset to be organized into meaningful semantic clusters that are pre-summarized.  The LLM uses these clusters to summarize these themes when responding to a user query. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```We illustrate whole-dataset reasoning abilities by posing the following question to the two systems:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>We illustrate whole-dataset reasoning abilities by posing the following question to the two systems: </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Query: “What are the top 5 themes in the data?“`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Looking at the results from baseline RAG, we see that none of the listed themes has much to do with the war between the two countries.  As anticipated, the vector search retrieved irrelevant text, which was inserted into the LLM’s context window.  Results that were included were likely keying on the word “theme,” resulting in a less than useful assessment of what is going on in the dataset.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Looking at the results from baseline RAG, we see that none of the listed themes has much to do with the war between the two countries.  As anticipated, the vector search retrieved irrelevant text, which was inserted into the LLM’s context window.  Results that were included were likely keying on the word “theme,” resulting in a less than useful assessment of what is going on in the dataset. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Observing the results from GraphRAG, we can clearly see that the results are far more aligned with what is going on in the dataset as a whole.  The answer provides the five main themes as well as supporting details that are observed in the dataset.  The referenced reports are pre-generated by the LLM for each semantic cluster in GraphRAG and, in turn, provide provenance back to original source material.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>Observing the results from GraphRAG, we can clearly see that the results are far more aligned with what is going on in the dataset as a whole.  The answer provides the five main themes as well as supporting details that are observed in the dataset.  The referenced reports are pre-generated by the LLM for each semantic cluster in GraphRAG and, in turn, provide provenance back to original source material.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Spotlight: On-demand video`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```AI Explainer: Foundation models ​and the next era of AI`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p class=\"large\">Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Creating LLM-generated knowledge graphs`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<h2 class=\"wp-block-heading\" id=\"creating-llm-generated-knowledge-graphs\">Creating LLM-generated knowledge graphs</h2>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```We note the basic flow that underpins GraphRAG, which builds upon our prior research (opens in new tab) and repositories (opens in new tab) using graph machine learning:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>We note the basic flow that underpins GraphRAG, which builds upon our prior <a href=\"https://www.microsoft.com/en-us/worklab/patterns-hidden-inside-the-org-chart\" rel=\"noreferrer noopener\" target=\"_blank\">research<span class=\"sr-only\"> (opens in new tab)</span></a> and <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/microsoft/graspologic\" rel=\"noreferrer noopener\" target=\"_blank\">repositories<span class=\"sr-only\"> (opens in new tab)</span></a> using graph machine learning: </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```An example visualization of the graph is shown in Figure 3.  Each circle is an entity (e.g., a person, place, or organization), with the entity size representing the number of relationships that entity has, and the color representing groupings of similar entities.  The color partitioning is a bottom-up clustering method built on top of the graph structure, which enables us to answer questions at varying levels of abstraction.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>An example visualization of the graph is shown in Figure 3.  Each circle is an entity (e.g., a person, place, or organization), with the entity size representing the number of relationships that entity has, and the color representing groupings of similar entities.  The color partitioning is a bottom-up clustering method built on top of the graph structure, which enables us to answer questions at varying levels of abstraction.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Result metrics`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```The illustrative examples above are representative of GraphRAG’s consistent improvement across multiple datasets in different subject domains.  We assess this improvement by performing an evaluation using an LLM grader to determine a pairwise winner between GraphRAG and baseline RAG.  We use a set of qualitative metrics, including comprehensiveness (completeness within the framing of the implied context of the question), human enfranchisement (provision of supporting source material or other contextual information), and diversity (provision of differing viewpoints or angles on the question posed). Initial results show that GraphRAG consistently outperforms baseline RAG on these metrics.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>The illustrative examples above are representative of GraphRAG’s consistent improvement across multiple datasets in different subject domains.  We assess this improvement by performing an evaluation using an LLM grader to determine a pairwise winner between GraphRAG and baseline RAG.  We use a set of qualitative metrics, including comprehensiveness (completeness within the framing of the implied context of the question), human enfranchisement (provision of supporting source material or other contextual information), and diversity (provision of differing viewpoints or angles on the question posed). Initial results show that GraphRAG <em>consistently outperforms </em>baseline RAG on these metrics.  </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```In addition to relative comparisons, we also use SelfCheckGPT (opens in new tab) to perform an absolute measurement of faithfulness to help ensure factual, coherent results grounded in the source material. Results show that GraphRAG achieves a similar level of faithfulness to baseline RAG. We are currently developing an evaluation framework to measure performance on the class of problems above.  This will include more robust mechanisms for generating question-answer test sets as well as additional metrics, such as accuracy and context relevance.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p>In addition to relative comparisons, we also use <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://arxiv.org/pdf/2303.08896.pdf\" rel=\"noreferrer noopener\" target=\"_blank\">SelfCheckGPT<span class=\"sr-only\"> (opens in new tab)</span></a> to perform an absolute measurement of faithfulness to help ensure factual, coherent results grounded in the source material. Results show that GraphRAG achieves a similar level of faithfulness to baseline RAG. We are currently developing an evaluation framework to measure performance on the class of problems above.  This will include more robust mechanisms for generating question-answer test sets as well as additional metrics, such as accuracy and context relevance. </p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Next steps`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```By combining LLM-generated knowledge graphs and graph machine learning, GraphRAG enables us to answer important classes of questions that we cannot attempt with baseline RAG alone.  We have seen promising results after applying this technology to a variety of scenarios, including social media, news articles, workplace productivity, and chemistry.  Looking forward, we plan to work closely with customers on a variety of new domains as we continue to apply this technology while working on metrics and robust evaluation. We look forward to sharing more as our research continues.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<p id=\"baseline-RAG\">By combining LLM-generated knowledge graphs and graph machine learning, GraphRAG enables us to answer important classes of questions that we cannot attempt with baseline RAG alone.  We have seen promising results after applying this technology to a variety of scenarios, including social media, news articles, workplace productivity, and chemistry.  Looking forward, we plan to work closely with customers on a variety of new domains as we continue to apply this technology while working on metrics and robust evaluation. We look forward to sharing more as our research continues.</p>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```1As baseline RAG in this comparison we use LangChain’s Q&A (opens in new tab), a well-known representative example of this class of RAG tools in widespread use today.`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Related publications`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "<h3 class=\"mb-0 h4\">\n",
      "<a class=\"js-card-link icon-link icon-link--card-title\" data-bi-cn=\"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine\" data-bi-type=\"publication\" href=\"https://www.microsoft.com/en-us/research/publication/can-generalist-foundation-models-outcompete-special-purpose-tuning-case-study-in-medicine/\" itemprop=\"url\">\n",
      "<span>Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine</span>\n",
      "<span aria-hidden=\"true\" class=\"c-heading__icon c-glyph glyph-chevron-right\"></span>\n",
      "</a>\n",
      "</h3>\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Meet the authors`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Jonathan Larson`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Senior Principal Data Architect`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Steven Truitt`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Principal Program Manager`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Continue reading`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Research Areas`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Related tools`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Follow us:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Share this page:`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Content Classifier):\n",
      "\n",
      "Title: `GraphRAG: Unlocking LLM discovery on narrative private data - Microsoft Research`, Data: ```Notifications`\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContent Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'viewport', 'content': 'width=device-width, initial-scale=1'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:dnt', 'content': 'on'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-product', 'content': 'MSR'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-stv', 'content': '8.5.0'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-sitesection', 'content': ''}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-pageType', 'content': 'Post'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-market', 'content': 'en-us'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-env', 'content': 'Production'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa‐asst', 'content': '1005408'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-pgidx', 'content': '1'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-pgtot', 'content': '-1'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'awa-pgtop', 'content': 'Artificial intelligence'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'robots', 'content': 'index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:locale', 'content': 'en_US'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:type', 'content': 'article'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:title', 'content': 'GraphRAG: A new approach for discovery using complex information'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:description', 'content': 'Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q&A when analyzing complex information and consistently outperforming baseline RAG. Get the details.'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:site_name', 'content': 'Microsoft Research'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'article:published_time', 'content': '2024-02-13T20:00:00+00:00'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'article:modified_time', 'content': '2024-02-13T16:50:07+00:00'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:image:width', 'content': '1200'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:image:height', 'content': '627'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'property': 'og:image:type', 'content': 'image/jpeg'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'author', 'content': 'Brenda Potts'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:card', 'content': 'summary_large_image'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:title', 'content': 'GraphRAG: A new approach for discovery using complex information'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:description', 'content': 'Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q&A when analyzing complex information and consistently outperforming baseline RAG. Get the details.'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:creator', 'content': '@MSFTResearch'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'twitter:site', 'content': '@MSFTResearch'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'generator', 'content': 'WordPress 6.4.3'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'name': 'research-area', 'content': 'Artificial intelligence'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'itemprop': 'width', 'content': '216'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'itemprop': 'height', 'content': '46'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'itemprop': 'name', 'content': 'Microsoft'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'itemprop': 'width', 'content': '1024'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to Metadata Classifier):\n",
      "\n",
      "We are parsing html metadata to extract useful data. Should we hold onto this item? {'itemprop': 'height', 'content': '576'}.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMetadata Classifier\u001b[0m (to ContentAgent):\n",
      "\n",
      "False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mContentAgent\u001b[0m (to user_proxy):\n",
      "\n",
      "Success: archived the following links in your chosen location ./content/ <-- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_history=[{'content': 'https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/', 'role': 'assistant'}, {'content': 'Success: archived the following links in your chosen location ./content/ <-- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/', 'role': 'user'}], summary='Success: archived the following links in your chosen location ./content/ <-- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/', cost=({'total_cost': 0}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/\"\n",
    "user_proxy.initiate_chat(web_archiver_agent, message=link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiex01_blog_hero_1400x788.png\n",
      "aiex01_blog_hero_1400x788.txt\n",
      "amit_emre_podcast_hero_feature_1400x788.jpg\n",
      "amit_emre_podcast_hero_feature_1400x788.txt\n",
      "content.txt\n",
      "emnlp-2023-blogherofeature-1400x788-1.png\n",
      "emnlp-2023-blogherofeature-1400x788-1.txt\n",
      "graphrag-blogherofeature-1400x788-1.png\n",
      "graphrag-blogherofeature-1400x788-1.txt\n",
      "graphrag-figure3.jpg\n",
      "graphrag-figure3.txt\n",
      "graphrag_figure1.png\n",
      "graphrag_figure1.txt\n",
      "graphrag_figure2.png\n",
      "graphrag_figure2.txt\n",
      "headshot150px.png\n",
      "headshot150px.txt\n",
      "index.html\n",
      "links.txt\n",
      "metadata.txt\n",
      "msr-ai-2x.png\n",
      "newsplitwise-jan-24-blogherofeature-1400x788-1.jpg\n",
      "newsplitwise-jan-24-blogherofeature-1400x788-1.txt\n",
      "screenshot.png\n",
      "sot-blogherofeature-1400x788-1.jpg\n",
      "sot-blogherofeature-1400x788-1.txt\n",
      "steven-truitt_360x360.jpg\n",
      "steven-truitt_360x360.txt\n"
     ]
    }
   ],
   "source": [
    "!ls {storage_path}/microsoft.com/graphrag-unlocking-llm-discovery-on-narrative-private-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for reference, what did the page look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_page = list(web_archiver_agent.process_history.keys())[-1]\n",
    "\n",
    "local_path = f\"{storage_path}/{get_file_path_from_url(last_page)}\"\n",
    "screenshot_path = os.path.join(local_path, \"screenshot.png\")\n",
    "assert os.path.exists(screenshot_path)\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(screenshot_path)\n",
    "\n",
    "# Display the image\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the bottom was cropped, but using the 'firefox' browser for our agent will trigger the \"full page screenshot\" function.<br>\n",
    "But not to worry, everything is also stored to disk in its original form, including the source HTML as it was loaded in the desktop browser.\n",
    "\n",
    "Below we confirm that our Autogen Agent successfully cataloged all of the content into the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We located our search term on line 14 out of a total 27 lines\n",
      "\n",
      "The last 3 lines stored in content were:\n",
      "\n",
      "In addition to relative comparisons, we also use SelfCheckGPT (opens in new tab) to perform an absolute measurement of faithfulness to help ensure factual, coherent results grounded in the source material. Results show that GraphRAG achieves a similar level of faithfulness to baseline RAG. We are currently developing an evaluation framework to measure performance on the class of problems above.  This will include more robust mechanisms for generating question-answer test sets as well as additional metrics, such as accuracy and context relevance.\n",
      "\n",
      "By combining LLM-generated knowledge graphs and graph machine learning, GraphRAG enables us to answer important classes of questions that we cannot attempt with baseline RAG alone.  We have seen promising results after applying this technology to a variety of scenarios, including social media, news articles, workplace productivity, and chemistry.  Looking forward, we plan to work closely with customers on a variety of new domains as we continue to apply this technology while working on metrics and robust evaluation. We look forward to sharing more as our research continues.\n",
      "\n",
      "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{local_path}/content.txt\") as f:\n",
    "    content = f.readlines()\n",
    "for idx, line in enumerate(content):\n",
    "    if \"What are the top 5\" in line:\n",
    "        break\n",
    "print(f\"We located our search term on line {idx} out of a total {len(content)} lines\\n\")\n",
    "print(\"The last 3 lines stored in content were:\\n\")\n",
    "for i in reversed(range(1, 4)):\n",
    "    print(content[-i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for looking at our new WebArchiverAgent:\n",
    "### Stay tuned for more updates from Autogen!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
